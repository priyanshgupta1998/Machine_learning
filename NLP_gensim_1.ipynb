{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gensim_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshgupta1998/Machine_learning/blob/master/NLP_gensim_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51IHJdRmNSvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8FFfFnoNS6-",
        "colab_type": "code",
        "outputId": "bef2cb99-aefd-4c11-83a0-dacbe2be71aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "TEMP_FOLDER = tempfile.gettempdir()\n",
        "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder \"/tmp\" will be used to save temporary dictionary and corpus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTeYAjMqOalv",
        "colab_type": "text"
      },
      "source": [
        "# From Strings to Vectors   \n",
        "\n",
        "we will be using 'gensim' python library to tokenize / vectorize the string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prwf_3BXNTUg",
        "colab_type": "code",
        "outputId": "b8d2446e-bfe3-4920-fd35-eed8efd1f761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "documents = [\"Human machine interface for lab abc computer applications\",\n",
        "             \"A survey of user opinion of computer system response time\",\n",
        "             \"The EPS user interface management system\",\n",
        "             \"System and human system engineering testing of EPS\",              \n",
        "             \"Relation of user perceived response time to error measurement\",\n",
        "             \"The generation of random binary unordered trees\",\n",
        "             \"The intersection graph of paths in trees\",\n",
        "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "             \"Graph minors A survey\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-14 06:43:06,931 : INFO : 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEtSm95aPCa0",
        "colab_type": "text"
      },
      "source": [
        "This is a tiny corpus of nine documents, each consisting of only a single sentence.\n",
        "\n",
        "First, let’s tokenize the documents, remove common words (Stopwords) as well as words that only appear once in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdzXJZLfNTbT",
        "colab_type": "code",
        "outputId": "f16f43c2-af07-4bbb-90ee-884e6f56fcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# remove common words and tokenize\n",
        "stoplist = set('for a of the and to in'.split())    # Some selected stopwords \n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]for document in documents]\n",
        "texts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
              " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
              " ['eps', 'user', 'interface', 'management', 'system'],\n",
              " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
              " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
              " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
              " ['intersection', 'graph', 'paths', 'trees'],\n",
              " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
              " ['graph', 'minors', 'survey']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZWl4UDNTZb",
        "colab_type": "code",
        "outputId": "bffc5e93-2b94-4749-f575-2c1e156b6876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "# remove words that appear only once\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "print(frequency)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'human': 2, 'machine': 1, 'interface': 2, 'lab': 1, 'abc': 1, 'computer': 2, 'applications': 1, 'survey': 2, 'user': 3, 'opinion': 1, 'system': 4, 'response': 2, 'time': 2, 'eps': 2, 'management': 1, 'engineering': 1, 'testing': 1, 'relation': 1, 'perceived': 1, 'error': 1, 'measurement': 1, 'generation': 1, 'random': 1, 'binary': 1, 'unordered': 1, 'trees': 3, 'intersection': 1, 'graph': 3, 'paths': 1, 'minors': 2, 'iv': 1, 'widths': 1, 'well': 1, 'quasi': 1, 'ordering': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7C5N4ggNTS9",
        "colab_type": "code",
        "outputId": "e5658083-b32f-4342-da8a-e3bab2567c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
        "\n",
        "from pprint import pprint  # pretty-printer\n",
        "pprint(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['human', 'interface', 'computer'],\n",
            " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
            " ['eps', 'user', 'interface', 'system'],\n",
            " ['system', 'human', 'system', 'eps'],\n",
            " ['user', 'response', 'time'],\n",
            " ['trees'],\n",
            " ['graph', 'trees'],\n",
            " ['graph', 'minors', 'trees'],\n",
            " ['graph', 'minors', 'survey']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uiDe0B4NTRJ",
        "colab_type": "code",
        "outputId": "1ec84573-9364-40fe-cbbf-aced457f0cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "dictionary = corpora.Dictionary(texts)\n",
        "dictionary.save(os.path.join(TEMP_FOLDER, 'deerwester.dict'))  # store the dictionary, for future reference\n",
        "print(dictionary) # dictionary has unique words."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-14 06:44:03,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2019-05-14 06:44:03,421 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
            "2019-05-14 06:44:03,422 : INFO : saving Dictionary object under /tmp/deerwester.dict, separately None\n",
            "2019-05-14 06:44:03,424 : WARNING : this function is deprecated, use smart_open.open instead\n",
            "2019-05-14 06:44:03,426 : INFO : saved /tmp/deerwester.dict\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DazSu2tqwLys",
        "colab_type": "text"
      },
      "source": [
        "### Here we assigned a unique integer ID to all words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzRQgmTpNTNx",
        "colab_type": "code",
        "outputId": "3d0e7d5c-7263-4dda-9998-e6347944002a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(dictionary.token2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl-Lx-QjwUnn",
        "colab_type": "text"
      },
      "source": [
        "### convert tokenized documents to vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gheLlFIyv6Qo",
        "colab_type": "code",
        "outputId": "23507e64-a094-4099-9f5a-dc0da581fee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_doc = \"Human computer interaction\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LphaBFxBv6Ta",
        "colab_type": "code",
        "outputId": "b59dc0bb-cd79-4e3f-bc35-c3d300396141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_doc = \"Human computer system\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (5, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkfGBjrPx4ej",
        "colab_type": "text"
      },
      "source": [
        "###  The function doc2bow() simply counts the number of occurrences of each distinct word, converts the word to its integer word id and returns the result as a bag-of-words--a sparse vector, in the form of [(word_id, word_count), ...]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x6Hxt3av6Oy",
        "colab_type": "code",
        "outputId": "298b81a9-8a78-48e5-d17e-73a8f23ddf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'deerwester.mm'), corpus)  # store to disk, for later use\n",
        "for c in corpus:\n",
        "    print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-14 06:44:25,727 : INFO : storing corpus in Matrix Market format to /tmp/deerwester.mm\n",
            "2019-05-14 06:44:25,730 : WARNING : this function is deprecated, use smart_open.open instead\n",
            "2019-05-14 06:44:25,731 : INFO : saving sparse matrix to /tmp/deerwester.mm\n",
            "2019-05-14 06:44:25,733 : INFO : PROGRESS: saving document #0\n",
            "2019-05-14 06:44:25,741 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
            "2019-05-14 06:44:25,746 : INFO : saving MmCorpus index to /tmp/deerwester.mm.index\n",
            "2019-05-14 06:44:25,748 : WARNING : this function is deprecated, use smart_open.open instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1)]\n",
            "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
            "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
            "[(1, 1), (5, 2), (8, 1)]\n",
            "[(3, 1), (6, 1), (7, 1)]\n",
            "[(9, 1)]\n",
            "[(9, 1), (10, 1)]\n",
            "[(9, 1), (10, 1), (11, 1)]\n",
            "[(4, 1), (10, 1), (11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4il4oQcFy9-",
        "colab_type": "text"
      },
      "source": [
        "### check the consistency between documents comparing their vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pHAoylKJtUN",
        "colab_type": "text"
      },
      "source": [
        "# Corpus Streaming – One Document at a Time\n",
        "\n",
        "iIt is clear that corpus above resides fully in memory, as a plain Python list. In this simple example, it doesn’t matter much, but just to make things clear, let’s assume there are millions of documents in the corpus.         \n",
        "we can't Store all of them in RAM . Instead of this , let’s assume the documents are stored in a file on disk, per line one document . Gensim only requires that a corpus  should be able to return one document vector at a time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm6yGfFqv6Ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#__iter__ is expected to return the next element of the iterable object that returned it, and raise a StopIteration exception when no more elements are\n",
        "#available.\n",
        "\n",
        "\n",
        "from smart_open import smart_open\n",
        "class MyCorpus(object):\n",
        "    def __iter__(self):\n",
        "        for line in smart_open('/home/corpora_docs.txt', 'rb'):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield dictionary.doc2bow(line.lower().split())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJcfR7oQv6Jf",
        "colab_type": "code",
        "outputId": "99e51806-2328-4271-87b9-53aa47f54130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corpus_memory_friendly = MyCorpus()    # it doesn't load the corpus into memory!\n",
        "print(corpus_memory_friendly)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.MyCorpus object at 0x7fad05b00208>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBrBwQ_oMF2N",
        "colab_type": "text"
      },
      "source": [
        "###  let’s iterate over the corpus and print each document vector (one at a time):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qTmuaqZNTKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for vector in corpus_memory_friendly:     # load one vector into memory at a time\n",
        "    print(vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDfb9gO3QZeh",
        "colab_type": "text"
      },
      "source": [
        "`Although the output is the same as for the plain Python list, the corpus is now much more memory friendly, because at most one vector resides in RAM at a time. Your corpus can now be as large as you want.   `                 \n",
        "\n",
        "\n",
        "`We are going to create the dictionary from the mycorpus.txt file without loading the entire file into memory. Then, we will generate the list of token ids to remove from this dictionary by querying the dictionary for the token ids of the stop words, and by querying the document frequencies dictionary (dictionary.dfs) for token ids that only appear once. Finally, we will filter these token ids out of our dictionary. Keep in mind that dictionary.filter_tokens (and some other functions such as dictionary.add_document) will call dictionary.compactify() to remove the gaps in the token id series thus enumeration of remaining tokens can be changed.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma4sVSBTNTIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from six import iteritems\n",
        "from smart_open import smart_open\n",
        "\n",
        "# collect statistics about all tokens\n",
        "dictionary = corpora.Dictionary(line.lower().split() for line in smart_open('/home/corpora_docs.txt', 'rb'))\n",
        "\n",
        "\n",
        "# remove stop words and words that appear only once\n",
        "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist \n",
        "            if stopword in dictionary.token2id]\n",
        "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
        "\n",
        "\n",
        "# remove stop words and words that appear only once\n",
        "dictionary.filter_tokens(stop_ids + once_ids)\n",
        "print(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sn6oZ7-NTGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcWOKjj0NTDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp1ChvArRSKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDAHhCG9RSID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPDjvvcqRSFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aZa2la_RSCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9PNFE8yNS5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1QEJs2qNS28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj59am2lNSzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}